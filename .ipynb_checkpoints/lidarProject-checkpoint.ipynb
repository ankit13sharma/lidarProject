{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uRY6Z2GOm3OB",
    "outputId": "0f41c0a3-3ff7-4913-94fe-5de82da86c38"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "VQ17vzxT9DfJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "from sklearn.cluster import KMeans as kmeans\n",
    "from sklearn.cluster import Birch\n",
    "# from h2o4gpu.solvers.kmeans import KMeans as kmeans\n",
    "# from h2o4gpu.cluster import Birch\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "zuPC8xK39nwP"
   },
   "outputs": [],
   "source": [
    "def read_data(path:str):\n",
    "    df = pd.read_csv(path, usecols = [0, 1, 2]) \n",
    "    df.columns = ['x','y','z']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "MbuMCF6QwVqk"
   },
   "outputs": [],
   "source": [
    "def apply_kmeans(df:pd.DataFrame,n_cl,cent):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function applies sklearns kmeans clustering algorithm. \n",
    "    It takes as input a dataframe with 2 coordinates x and y  along with two parameters for initialization\n",
    "    namely number of clusters and their centers.\n",
    "    It returns labels, cluster centers, predicted label and distance from cluster centers respectively \n",
    "    \"\"\"\n",
    "    \n",
    "    kmn = kmeans(n_clusters=n_cl, init = cent, n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=36, copy_x=True, n_jobs=None, algorithm='auto').fit(df[['x','y']])\n",
    "    label = kmn.labels_\n",
    "    out = kmn.predict(df[['x','y']])\n",
    "    cent = kmn.cluster_centers_\n",
    "    dist = kmn.transform(df[['x','y']])\n",
    "    agmn = np.argmin(dist, axis = 1)\n",
    "    c_dist = np.empty_like(agmn, dtype = np.float32)\n",
    "    for dst in range(len(agmn)):\n",
    "        c_dist[dst] = dist[dst, agmn[dst]]    \n",
    "    return (label,cent,out,c_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "q5Jz4s19Ujju"
   },
   "outputs": [],
   "source": [
    "def apply_birch(df:pd.DataFrame,th):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function applies sklearns birch clustering algorithm. \n",
    "    It takes as input a dataframe with 2 coordinates x and y  along with a parameters called thresholding factor \n",
    "    for initialization of birch\n",
    "    It returns labels, cluster centers, predicted label and distance from cluster centers respectively \n",
    "    \"\"\"\n",
    "    \n",
    "    data = df[['x','y']]\n",
    "    brc = Birch(branching_factor=50, n_clusters=None, threshold=th, compute_labels=True)\n",
    "    brc.fit(data)\n",
    "    label = brc.predict(data)\n",
    "    out = brc.labels_\n",
    "    \n",
    "    cent = brc.subcluster_centers_\n",
    "    dist = brc.transform(data)\n",
    "    agmn = np.argmin(dist, axis = 1)\n",
    "    c_dist = np.empty_like(agmn, dtype = np.float32)\n",
    "    for dst in range(len(agmn)):\n",
    "        c_dist[dst] = dist[dst, agmn[dst]]    \n",
    "    return (label,cent,out,c_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "BWgX3dDR7765"
   },
   "outputs": [],
   "source": [
    "def plot_kmeans(X,Y,Z,label,cent):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function plots results of kmeans prediction along with cluster centers\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in list(np.unique(label)):\n",
    "        x = X[label.ravel()==i]\n",
    "        y = Y[label.ravel()==i]\n",
    "        z = Z[label.ravel()==i]\n",
    "        plt.scatter(x,y)\n",
    "    plt.scatter(cent[:,0],cent[:,1],s = 80,c = 'y', marker = 's')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "yzXhW-ocH9Wi"
   },
   "outputs": [],
   "source": [
    "def adapt_buffer(x1,y1,z1,r1,lbl):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function applies a buffer to the cluster adaptively. It operates on 2 dimentional[r,z] data \n",
    "    instead of 3 dimentional[x,y,z].It runs until convergence. In every iteration it first computes \n",
    "    the center position(ric1,z1c1) and then recomputes radial distance from center r. it then removes \n",
    "    the points that lie beyond average of (min of r (supposed trunk boundary) and max of r (cluster boundary)).\n",
    "    It then recomputes the center boundary and uses the change in center position (r) for loop termination criteria.\n",
    "    \n",
    "    It returns the lists of reduced points(x,y,z,r)\n",
    "    \"\"\"\n",
    "    \n",
    "    esp = 100\n",
    "    k = 0\n",
    "    l1 = len(r1)\n",
    "    while esp > 0.0001 and k<1000 and len(x1)>100:\n",
    "        r1c1 = np.average(r1)\n",
    "        z1c1 = np.average(z1)\n",
    "        r1 = (r1-r1c1)\n",
    "        l1 = len(r1)\n",
    "        \n",
    "        z1 = (z1[(r1<(min(np.absolute(r1))+max(np.absolute(r1)))/2)]).reshape(-1,1)\n",
    "        x1 = (x1[(r1<(min(np.absolute(r1))+max(np.absolute(r1)))/2)]).reshape(-1,1)\n",
    "        y1 = (y1[(r1<(min(np.absolute(r1))+max(np.absolute(r1)))/2)]).reshape(-1,1)\n",
    "        r1 = (r1[(r1<(min(np.absolute(r1))+max(np.absolute(r1)))/2)]).reshape(-1,1)\n",
    "        \n",
    "        l2 = len(r1)\n",
    "        r1c2 = np.average(r1)\n",
    "        esp = 100*(np.absolute(r1c1 - r1c2))/(np.absolute(r1c1)+1)\n",
    "        #esp = 100*(l1-l2)/(l1)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    f_l1 = (np.ones(len(x1))*lbl).reshape(-1,1)\n",
    "    return (x1,y1,z1,r1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "hJ0mzlvtA1xy"
   },
   "outputs": [],
   "source": [
    "def zr_adjust(x1,y1,z1,r1,it_max):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is inspired from Mohr circle representation. It computes the center(r2m) and radius(rd) \n",
    "    of mohr circle that is formed by boundaries of all points lying in a cluster. It iteratively searches \n",
    "    for the tree trunk in the mohr circle using binary search algorithm.In every iteration it compares the density \n",
    "    (number of points factored by height range for that region) of points\n",
    "    lying in each of the two regions (inner circle and outer ring) of mohr circle and selects the region with higher density\n",
    "    (more likely to contain the trunk).It repeats the search until convergence. \n",
    "    The percentage change in the density of two regions is used as convergence criteria.\n",
    "    Finally it returns the subset of points lying within the region most likely to contain the trunk.\n",
    "    \"\"\"\n",
    "    \n",
    "    esp2 = 100\n",
    "    kl = 0\n",
    "    r2 = r1\n",
    "    while esp2 > 0.0001 and kl <it_max and len(r2)>50:\n",
    "        r2mn = np.min(r2)\n",
    "        r2mx = np.max(r2)\n",
    "        r2m = (r2mn + r2mx)/2\n",
    "        rd = (r2mx -r2mn)/2 \n",
    "        \n",
    "        r2 = r2 - r2m\n",
    "        \n",
    "        z11 = z1[(r2 <= rd/2) & (r2>= -rd/2)]\n",
    "        z12 = z1[(r2 > rd/2) & (r2<= -rd/2)]\n",
    "        fc1 = len(z11)\n",
    "        fc2 = len(z12)\n",
    "        fc = np.absolute(fc1-fc2)\n",
    "        if fc1>fc2:\n",
    "            esp2 = 100*fc/fc1\n",
    "            kl += 1\n",
    "    \n",
    "            ir1 = -rd/2\n",
    "            ir2 = rd/2\n",
    "\n",
    "            \n",
    "        else:\n",
    "            z21 = z1[(r2 >= rd/2) & (r2<= rd)]\n",
    "            z22 = z1[(r2 >= -rd) & (r2<= -rd/2)]\n",
    "            fc1 = len(z21)*np.ptp(z21)\n",
    "            fc2 = len(z22)*np.ptp(z22)\n",
    "            fc = np.absolute(fc1-fc2)\n",
    "            \n",
    "            if fc1>fc2:\n",
    "                esp2 = 100*fc/fc1\n",
    "                kl += 1\n",
    "\n",
    "                ir1 = rd/2\n",
    "                ir2 = rd\n",
    "                \n",
    "            else:\n",
    "                esp2 = 100*fc/fc2\n",
    "                kl += 1\n",
    "\n",
    "                ir1 = -rd\n",
    "                ir2 = -rd/2\n",
    "                                 \n",
    "        \n",
    "        r1 = r1[(r2>=ir1) & (r2<=ir2)]\n",
    "        r1 = r1.reshape(-1,1)\n",
    "        x1 = x1[(r2>=ir1) & (r2<=ir2)]\n",
    "        x1 = x1.reshape(-1,1)\n",
    "        y1 = y1[(r2>=ir1) & (r2<=ir2)]\n",
    "        y1 = y1.reshape(-1,1)\n",
    "        z1 = z1[(r2>=ir1) & (r2<=ir2)]\n",
    "        z1 = z1.reshape(-1,1)\n",
    "        r2 = r2[(r2>=ir1) & (r2<=ir2)]\n",
    "        r2 = r2.reshape(-1,1)\n",
    "\n",
    "    return (x1,y1,z1,r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "5bTMyPcGQ7ys"
   },
   "outputs": [],
   "source": [
    "def x_finder(x1,y1,z1,r1,step,itmax):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is similar to zr_adjust function. But it searches for the trunk in x dimension instead of r. \n",
    "    It is applied after trunk is already located in r dimention using zr_adjust function.  \n",
    "    \"\"\"\n",
    "    \n",
    "    esp2 = 100\n",
    "    kl = 0\n",
    "    x_2 = x1\n",
    "    while esp2 > 10 and kl<itmax and np.ptp(x_2) > 0.5 and len(x_2)> step:\n",
    "        \n",
    "        x2mn = np.min(x_2)\n",
    "        x2mx = np.max(x_2)\n",
    "        x2m = (x2mn + x2mx)/2\n",
    "        \n",
    "        z11 = z1[(x1 >= x2mn) & (x1 <= x2m)]\n",
    "        z12 = z1[(x1 > x2m) & (x1 <= x2mx)]\n",
    "        fc1 = len(z11)*np.ptp(z11)\n",
    "        fc2 = len(z12)*np.ptp(z12)\n",
    "        fc = np.absolute(fc1-fc2)\n",
    "        if fc1>fc2:\n",
    "            ix1 = x2mn\n",
    "            ix2 = x2m\n",
    "            \n",
    "            x_2 = x_2[(x_2>=ix1) & (x_2<=ix2)]\n",
    "            x_2 = x_2.reshape(-1,1)\n",
    "        \n",
    "            esp2 = 100*fc/fc1\n",
    "            kl += 1\n",
    "    \n",
    "        else:\n",
    "            ix1 = x2m\n",
    "            ix2 = x2mx\n",
    "            x_2 = x_2[(x_2>=ix1) & (x_2<=ix2)]\n",
    "            x_2 = x_2.reshape(-1,1)\n",
    "            esp2 = 100*fc/fc2\n",
    "            kl += 1\n",
    "    \n",
    "    ix1 = np.min(x_2)\n",
    "    ix2 = np.max(x_2)\n",
    "    r1 = r1[(x1>=ix1) & (x1<=ix2)]\n",
    "    y1 = y1[(x1>=ix1) & (x1<=ix2)]\n",
    "    z1 = z1[(x1>=ix1) & (x1<=ix2)]\n",
    "    x1 = x1[(x1>=ix1) & (x1<=ix2)]\n",
    "    \n",
    "\n",
    "    x1 = x1.reshape(-1,1)\n",
    "    y1 = y1.reshape(-1,1)\n",
    "    z1 = z1.reshape(-1,1)\n",
    "    r1 = r1.reshape(-1,1)\n",
    "    return (x1,y1,z1,r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "7f-3MVSkO-Br"
   },
   "outputs": [],
   "source": [
    "def plot_3d(X_sub, Y_sub, Z_sub, l_sub):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function plots each cluster in a 3d projection\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Elevation')\n",
    "    for lbl in list(np.unique(l_sub)):\n",
    "        ax.scatter(X_sub[l_sub == lbl], Y_sub[l_sub == lbl], Z_sub[l_sub == lbl])\n",
    "\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "kt7dL0d7P866"
   },
   "outputs": [],
   "source": [
    "def plot_2d(X_sub, Y_sub, Z_sub, l_sub):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function plots each cluster in a 2d projection\n",
    "    \"\"\"\n",
    "    \n",
    "    for lbl in list(np.unique(l_sub)):\n",
    "        plt.scatter(X_sub[l_sub == lbl], Y_sub[l_sub == lbl], Z_sub[l_sub == lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "7lssTTMhXoJa"
   },
   "outputs": [],
   "source": [
    "def sub_set(X,Y,Z,label,hm,hc):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function subset the data points in each cluster based on height. it takes as argument\n",
    "    the three coordinates of datapoints, their cluster labels, lower height cutoff hm \n",
    "    and fraction of height factor hc for upper limit.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    X_sub =np.empty((1,1))\n",
    "    Y_sub =np.empty((1,1))\n",
    "    Z_sub =np.empty((1,1))\n",
    "    l_sub = np.empty((1,1))\n",
    "\n",
    "\n",
    "    for lbl in list(np.unique(label)):\n",
    "        x1 = (X[label == lbl]).reshape(-1,1)\n",
    "        y1 = (Y[label == lbl]).reshape(-1,1) \n",
    "        z1 = (Z[label == lbl]).reshape(-1,1)\n",
    "        \n",
    "        x1 = (x1[(z1>(min(z1)+hm)) & (z1<min(z1)+hm+min(tree_H[lbl]*hc, 20))]).reshape(-1,1)\n",
    "        y1 = (y1[(z1>(min(z1)+hm)) & (z1<min(z1)+hm+min(tree_H[lbl]*hc, 20))]).reshape(-1,1)\n",
    "        z1 = (z1[(z1>(min(z1)+hm)) & (z1<min(z1)+hm+min(tree_H[lbl]*hc, 20))]).reshape(-1,1)\n",
    "        \n",
    "        X_sub = np.concatenate((X_sub,x1))\n",
    "        Y_sub = np.concatenate((Y_sub,y1))\n",
    "        Z_sub = np.concatenate((Z_sub,z1))\n",
    "        \n",
    "        f_l1 = (np.ones(len(x1))*lbl).reshape(-1,1)\n",
    "        \n",
    "        l_sub = np.concatenate((l_sub,f_l1))\n",
    "    \n",
    "    X_sub = (X_sub).reshape(-1,1)\n",
    "    Y_sub = (Y_sub).reshape(-1,1)\n",
    "    Z_sub = (Z_sub).reshape(-1,1)\n",
    "    l_sub = (l_sub).reshape(-1,1)\n",
    "\n",
    "    X_sub = X_sub[1:,:]\n",
    "    Y_sub = Y_sub[1:,:]\n",
    "    Z_sub = Z_sub[1:,:]\n",
    "    \n",
    "    l_sub = l_sub[1:,:]\n",
    "    \n",
    "    return (X_sub, Y_sub, Z_sub, l_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "u-j9P64x1Az2"
   },
   "outputs": [],
   "source": [
    "def ad_buffer(X_sub, Y_sub, Z_sub, c_dist2, label2,k_max):\n",
    "\n",
    "    X_sub2 =np.empty((1,1))\n",
    "    Y_sub2 =np.empty((1,1))\n",
    "    Z_sub2 =np.empty((1,1))\n",
    "    R_sub2 = np.empty((1,1))\n",
    "    f_sub2 = np.empty((1,1))\n",
    "    fx_sub2 = np.empty((1,1))\n",
    "    l_sub2 = np.empty((1,1))\n",
    "\n",
    "\n",
    "    for lbl in list(np.unique(label2)):\n",
    "        x1 = list(X_sub[label2 == lbl])\n",
    "        y1 = list(Y_sub[label2 == lbl])   \n",
    "        z1 = list(Z_sub[label2 == lbl])\n",
    "        r1 = list(c_dist2[label2 == lbl])\n",
    "        \n",
    "        \n",
    "        \n",
    "        z1 = (np.array(z1)).reshape(-1,1)\n",
    "        r1 = (np.array(r1)).reshape(-1,1)\n",
    "        x1 = (np.array(x1)).reshape(-1,1)\n",
    "        y1 = (np.array(y1)).reshape(-1,1)\n",
    "        \n",
    "        x1,y1,z1,r1 = adapt_buffer(x1,y1,z1,r1,lbl)\n",
    "        \n",
    "        \n",
    "        X_sub2 = np.concatenate((X_sub2,x1))\n",
    "        Y_sub2 = np.concatenate((Y_sub2,y1))\n",
    "        Z_sub2 = np.concatenate((Z_sub2,z1))\n",
    "        \n",
    "        f_num1 = (np.arange(len(r1))).reshape(-1,1)\n",
    "                \n",
    "        f_x1 = (np.arange(len(r1))).reshape(-1,1)\n",
    "        f_l1 = (np.ones(len(x1))*lbl).reshape(-1,1)\n",
    "        \n",
    "        l_sub2 = np.concatenate((l_sub2,f_l1))\n",
    "        fx_sub2 = np.concatenate((fx_sub2,f_x1))\n",
    "        f_sub2 = np.concatenate((f_sub2,f_num1))\n",
    "        R_sub2 = np.concatenate((R_sub2,r1))\n",
    "\n",
    "        f_x1 = f_x1.reshape(-1,)\n",
    "        f_num1 = f_num1.reshape(-1,)\n",
    "        \n",
    "    \n",
    "    X_sub2 = (X_sub2).reshape(-1,1)\n",
    "    Y_sub2 = (Y_sub2).reshape(-1,1)\n",
    "    Z_sub2 = (Z_sub2).reshape(-1,1)\n",
    "    f_sub2 = (f_sub2).reshape(-1,1)\n",
    "    fx_sub2 = (fx_sub2).reshape(-1,1)\n",
    "    l_sub2 = (l_sub2).reshape(-1,1)\n",
    "    R_sub2 = (R_sub2).reshape(-1,1)\n",
    "\n",
    "\n",
    "    X_sub2 = X_sub2[1:,:]\n",
    "    Y_sub2 = Y_sub2[1:,:]\n",
    "    Z_sub2 = Z_sub2[1:,:]\n",
    "    f_sub2 = f_sub2[1:,:]\n",
    "    fx_sub2 = fx_sub2[1:,:]\n",
    "    l_sub2 = l_sub2[1:,:]\n",
    "    R_sub2 = R_sub2[1:,:]\n",
    "\n",
    "    return (X_sub2, Y_sub2, Z_sub2, R_sub2, l_sub2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "wb6XoT186cl4"
   },
   "outputs": [],
   "source": [
    "def apply_zr(X_sub2, Y_sub2, Z_sub2, R_sub2, l_sub2,it_max):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function applies zr_adjust function for each cluster\n",
    "    \"\"\"\n",
    "    \n",
    "    X_sub3 =np.empty((1,1))\n",
    "    Y_sub3 =np.empty((1,1))\n",
    "    Z_sub3 =np.empty((1,1))\n",
    "    R_sub3 = np.empty((1,1))\n",
    "    f_sub3 = np.empty((1,1))\n",
    "    fx_sub3 = np.empty((1,1))\n",
    "    l_sub3 = np.empty((1,1))\n",
    "\n",
    "    for lbl in list(np.unique(l_sub2)):\n",
    "        x1 = list(X_sub2[l_sub2 == lbl])\n",
    "        y1= list(Y_sub2[l_sub2 == lbl])   \n",
    "        z1 = list(Z_sub2[l_sub2 == lbl])\n",
    "        r1 = list(R_sub2[l_sub2 == lbl])\n",
    "        z1,r1,x1,y1 = zip(*sorted(zip(z1, r1,x1,y1)))\n",
    "        z1 = (np.array(z1)).reshape(-1,1)\n",
    "        r1 = (np.array(r1)).reshape(-1,1)\n",
    "        x1 = (np.array(x1)).reshape(-1,1)\n",
    "        y1 = (np.array(y1)).reshape(-1,1)\n",
    "        \n",
    "        if len(r1)>10:\n",
    "            x1,y1,z1,r1 = zr_adjust(x1,y1,z1,r1,it_max)        \n",
    "        \n",
    "        X_sub3 = np.concatenate((X_sub3,x1))\n",
    "        Y_sub3 = np.concatenate((Y_sub3,y1))\n",
    "        Z_sub3 = np.concatenate((Z_sub3,z1))\n",
    "        \n",
    "        f_num1 = (np.arange(len(r1))).reshape(-1,1)\n",
    "                \n",
    "        f_x1 = (np.arange(len(r1))).reshape(-1,1)\n",
    "        f_l1 = (np.ones(len(x1))*lbl).reshape(-1,1)\n",
    "        \n",
    "\n",
    "        \n",
    "        l_sub3 = np.concatenate((l_sub3,f_l1))\n",
    "        fx_sub3 = np.concatenate((fx_sub3,f_x1))\n",
    "        f_sub3 = np.concatenate((f_sub3,f_num1))\n",
    "        R_sub3 = np.concatenate((R_sub3,r1))\n",
    "        \n",
    "        \n",
    "        f_x1 = f_x1.reshape(-1,)\n",
    "        f_num1 = f_num1.reshape(-1,)\n",
    "        \n",
    "    \n",
    "    X_sub3 = (X_sub3).reshape(-1,1)\n",
    "    Y_sub3 = (Y_sub3).reshape(-1,1)\n",
    "    Z_sub3 = (Z_sub3).reshape(-1,1)\n",
    "    f_sub3 = (f_sub3).reshape(-1,1)\n",
    "    fx_sub3 = (fx_sub3).reshape(-1,1)\n",
    "    l_sub3 = (l_sub3).reshape(-1,1)\n",
    "    R_sub3 = (R_sub3).reshape(-1,1)\n",
    "\n",
    "\n",
    "    X_sub3 = X_sub3[1:,:]\n",
    "    Y_sub3 = Y_sub3[1:,:]\n",
    "    Z_sub3 = Z_sub3[1:,:]\n",
    "    f_sub3 = f_sub3[1:,:]\n",
    "    fx_sub3 = fx_sub3[1:,:]\n",
    "    l_sub3 = l_sub3[1:,:]\n",
    "    R_sub3 = R_sub3[1:,:]\n",
    "\n",
    "    return(X_sub3, Y_sub3, Z_sub3, R_sub3, l_sub3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "G3J4SSTXCqer"
   },
   "outputs": [],
   "source": [
    "def apply_finder(X_sub3, Y_sub3, Z_sub3, R_sub3, l_sub3,itmax):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function applies x_finder function twice first in x dimension followed by y dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    X_sub4 =np.empty((1,1))\n",
    "    Y_sub4 =np.empty((1,1))\n",
    "    Z_sub4 =np.empty((1,1))\n",
    "    R_sub4 = np.empty((1,1))\n",
    "    l_sub4 = np.empty((1,1))\n",
    "\n",
    "    for lbl in list(np.unique(l_sub3)):\n",
    "        x1 = list(X_sub3[l_sub3 == lbl])\n",
    "        y1= list(Y_sub3[l_sub3 == lbl])   \n",
    "        z1 = list(Z_sub3[l_sub3 == lbl])\n",
    "        r1 = list(R_sub3[l_sub3 == lbl])\n",
    "        z1,r1,x1,y1 = zip(*sorted(zip(z1, r1,x1,y1)))\n",
    "        z1 = (np.array(z1)).reshape(-1,1)\n",
    "        r1 = (np.array(r1)).reshape(-1,1)\n",
    "        x1 = (np.array(x1)).reshape(-1,1)\n",
    "        y1 = (np.array(y1)).reshape(-1,1)\n",
    "        \n",
    "        if len(r1)>10:\n",
    "            x1,y1,z1,r1 = x_finder(x1,y1,z1,r1,25,itmax)        \n",
    "        if len(r1)>10:\n",
    "            y1,x1,z1,r1 = x_finder(y1,x1,z1,r1,10,itmax)        \n",
    "        \n",
    "        X_sub4 = np.concatenate((X_sub4,x1))\n",
    "        Y_sub4 = np.concatenate((Y_sub4,y1))\n",
    "        Z_sub4 = np.concatenate((Z_sub4,z1))\n",
    "        \n",
    "        f_l1 = (np.ones(len(x1))*lbl).reshape(-1,1)\n",
    "        \n",
    "\n",
    "        l_sub4 = np.concatenate((l_sub4,f_l1))\n",
    "        R_sub4 = np.concatenate((R_sub4,r1))\n",
    "\n",
    "    \n",
    "    X_sub4 = (X_sub4).reshape(-1,1)\n",
    "    Y_sub4 = (Y_sub4).reshape(-1,1)\n",
    "    Z_sub4 = (Z_sub4).reshape(-1,1)\n",
    "    l_sub4 = (l_sub4).reshape(-1,1)\n",
    "    R_sub4 = (R_sub4).reshape(-1,1)\n",
    "\n",
    "\n",
    "    X_sub4 = X_sub4[1:,:]\n",
    "    Y_sub4 = Y_sub4[1:,:]\n",
    "    Z_sub4 = Z_sub4[1:,:]\n",
    "    l_sub4 = l_sub4[1:,:]\n",
    "    R_sub4 = R_sub4[1:,:]\n",
    "\n",
    "    return (X_sub4, Y_sub4, Z_sub4, R_sub4, l_sub4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "RCaKDy_z9YXF"
   },
   "outputs": [],
   "source": [
    "def width_finder(px, py, pz,pl):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function computes the depth at breast height (dbh) parameter \n",
    "    for all clusters/trees using the median value of width of all clusters/trees\n",
    "    \"\"\"\n",
    "    \n",
    "    w = []\n",
    "    for lbl in list(np.unique(pl)):\n",
    "        x1,y1,z1 = px[pl == lbl], py[pl == lbl], pz[pl == lbl]\n",
    "        \n",
    "        if len(x1)<=1:\n",
    "            #print('not enough points')\n",
    "            w1 = 0\n",
    "            #continue\n",
    "        else:\n",
    "            w1 = max(np.ptp(x1),np.ptp(y1))\n",
    "            #print('width:', w1)\n",
    "        w.append(w1)\n",
    "    w = (np.array(w)).reshape(-1,1)\n",
    "    dbh = np.median(w)\n",
    "    #print('Median DBH:', dbh)\n",
    "    return w,dbh\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(df:pd.DataFrame):\n",
    "    for _ in range(df.shape[1]):\n",
    "        df = df[(np.abs(stats.zscore(df.iloc[:,i:i+1])) <3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "ki-KPy-G-CtD"
   },
   "outputs": [],
   "source": [
    "path = './Full_Point.csv'\n",
    "dataset = read_data(path)\n",
    "\n",
    "# QC check. removing outliers\n",
    "\n",
    "\n",
    "# del arr1\n",
    "# dataset1 = dataset[(stats.zscore(dataset.iloc[:,3:4]) < 1.96).all(axis=1)]\n",
    "# dataset = dataset[(np.abs(stats.zscore(dataset.iloc[:,:])) < 2.96).all(axis=1)]\n",
    "# arr1 = np.array(dataset)\n",
    "# del dataset\n",
    "\n",
    "X = dataset['x']\n",
    "Y = dataset['y']\n",
    "Z = dataset['z']\n",
    "    \n",
    "xmax, xmin = np.max(X), np.min(X)\n",
    "ymax, ymin = np.max(Y), np.min(Y)\n",
    "xm = (xmax + xmin)/2\n",
    "ym = (ymax + ymin)/2\n",
    "X1 = X[(X<=xm) & (X>=xmin) & (Y<=ym) & (Y>=ymin)]\n",
    "Y1 = Y[(X<=xm) & (X>=xmin) & (Y<=ym) & (Y>=ymin)]\n",
    "Z1 = Z[(X<=xm) & (X>=xmin) & (Y<=ym) & (Y>=ymin)]\n",
    "\n",
    "X2 = X[(X<=xmax) & (X>=xm) & (Y<=ym) & (Y>=ymin)]\n",
    "Y2 = Y[(X<=xmax) & (X>=xm) & (Y<=ym) & (Y>=ymin)]\n",
    "Z2 = Z[(X<=xmax) & (X>=xm) & (Y<=ym) & (Y>=ymin)]\n",
    "\n",
    "X3 = X[(X<=xm) & (X>=xmin) & (Y<=ymax) & (Y>=ym)]\n",
    "Y3 = Y[(X<=xm) & (X>=xmin) & (Y<=ymax) & (Y>=ym)]\n",
    "Z3 = Z[(X<=xm) & (X>=xmin) & (Y<=ymax) & (Y>=ym)]\n",
    "\n",
    "X4 = X[(X<=xmax) & (X>=xm) & (Y<=ymax) & (Y>=ym)]\n",
    "Y4 = Y[(X<=xmax) & (X>=xm) & (Y<=ymax) & (Y>=ym)]\n",
    "Z4 = Z[(X<=xmax) & (X>=xm) & (Y<=ymax) & (Y>=ym)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "p92KX21X_clF",
    "outputId": "da8b0c2d-7f4f-44c1-99f3-1f7481111938"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.25400000000445 21.983000000000175\n"
     ]
    }
   ],
   "source": [
    "print((xmax-xmin),(ymax-ymin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ypq0wlKE-n3Z",
    "outputId": "4e46ba8c-64ea-4663-8940-69519faf1fca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.35000000000002\n"
     ]
    }
   ],
   "source": [
    "print(np.max(Z) - np.min(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "um4MxfbFmqc5"
   },
   "outputs": [],
   "source": [
    "arr = np.empty((len(X3),3))\n",
    "arr[:,0] = np.array(X3)\n",
    "arr[:,1] = np.array(Y3)\n",
    "arr[:,2] = np.array(Z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "s9zgg-SG2s1p"
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'Column1': X1, 'Column2': Y1,'Column3': Z1})\n",
    "dataset.to_csv('./grid1_subset_subset_input3.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "nfyur7cPmqc8",
    "outputId": "cff601b4-4026-4c9e-ee3a-035db16dc703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -23161.739\n",
      "1   -23161.572\n",
      "2   -23161.765\n",
      "3   -23161.294\n",
      "4   -23161.356\n",
      "Name: x, dtype: float64\n",
      "0   -36750.609\n",
      "1   -36750.729\n",
      "2   -36750.733\n",
      "3   -36750.827\n",
      "4   -36750.489\n",
      "Name: y, dtype: float64\n",
      "0    335.46\n",
      "1    335.32\n",
      "2    335.32\n",
      "3    335.19\n",
      "4    335.57\n",
      "Name: z, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X1[:5])\n",
    "print(Y1[:5])\n",
    "print(Z1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gbMgs4rysKvb",
    "outputId": "5602121b-c104-4a84-fcc1-1492a859a110",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5, 3, 4.5, 6, 7.5]\n",
      "[0.5, 0.37, 0.25]\n",
      "[2, 4, 6]\n",
      "21.983000000000175 36.25400000000445\n",
      "label done\n",
      "(1048575, 1) (1048575, 1) 6 (6,)\n",
      "height computed\n",
      "29.14 40.08 35.52\n",
      "0 :  0.3849999999947613\n",
      "1 :  0.41199999999662396\n",
      "2 :  0.42300000000250293\n",
      "3 :  0.42800000000352156\n",
      "4 :  0.39099999999962165\n",
      "5 :  0.4220000000022992\n",
      "6 :  0.4639999999999418\n",
      "7 :  0.41000000000349246\n",
      "8 :  0.47699999999895226\n",
      "9 :  0.40450000000419095\n",
      "10 :  0.4290000000000873\n",
      "11 :  0.4320000000006985\n",
      "12 :  0.46200000000135333\n",
      "13 :  0.3889999999992142\n",
      "14 :  0.4210000000002765\n",
      "15 :  0.5750000000007276\n",
      "16 :  0.4789999999993597\n",
      "17 :  0.6239999999997963\n",
      "18 :  0.4219999999986612\n",
      "19 :  0.43000000000211\n",
      "20 :  0.43000000000211\n",
      "21 :  0.4830000000038126\n",
      "22 :  0.45900000000256114\n",
      "23 :  0.4900000000016007\n",
      "24 :  0.4625000000014552\n",
      "25 :  0.3555000000014843\n",
      "26 :  0.41049999999813735\n",
      "27 :  0.3739999999961583\n",
      "28 :  0.3800000000046566\n",
      "29 :  0.3849999999983993\n",
      "30 :  0.42899999999644933\n",
      "31 :  0.36300000000483124\n",
      "32 :  0.4090000000069267\n",
      "33 :  0.4664999999986321\n",
      "34 :  0.4370000000017171\n",
      "35 :  0.4569999999985157\n",
      "36 :  0.40050000000337604\n",
      "37 :  0.41750000000138243\n",
      "38 :  0.4205000000019936\n",
      "39 :  0.419000000001688\n",
      "40 :  0.3960000000006403\n",
      "41 :  0.41899999999805004\n",
      "42 :  0.6639999999970314\n",
      "43 :  0.46300000000337604\n",
      "44 :  0.4970000000030268\n",
      "45 :  0.39900000000307045\n",
      "46 :  0.41749999999956344\n",
      "47 :  0.41749999999956344\n",
      "48 :  0.4195000000017899\n",
      "49 :  0.42550000000483124\n",
      "50 :  0.4530000000013388\n",
      "51 :  0.49499999999898137\n",
      "52 :  0.44799999999668216\n",
      "53 :  0.6620000000038999\n",
      "54 :  0.40399999999681313\n",
      "55 :  0.3794999999990978\n",
      "56 :  0.3930000000018481\n",
      "57 :  0.4749999999985448\n",
      "58 :  0.3550000000032014\n",
      "59 :  0.43699999999807915\n",
      "60 :  0.6514999999999418\n",
      "61 :  0.43149999999877764\n",
      "62 :  0.38950000000477303\n",
      "63 :  0.39399999999841384\n",
      "64 :  0.40899999999965075\n",
      "65 :  0.4150000000008731\n",
      "66 :  0.4455000000016298\n",
      "67 :  0.43149999999877764\n",
      "68 :  0.44949999999880674\n",
      "69 :  0.4029999999984284\n",
      "70 :  0.3570000000036089\n",
      "71 :  0.4029999999984284\n",
      "72 :  0.37800000000243017\n",
      "73 :  0.4375\n",
      "74 :  0.4379999999946449\n",
      "75 :  0.41749999999956344\n",
      "76 :  0.3900000000012369\n",
      "77 :  0.4530000000013388\n",
      "78 :  0.4569999999948777\n",
      "79 :  0.4239999999990687\n",
      "80 :  0.48400000000401633\n",
      "81 :  0.4000000000014552\n",
      "82 :  0.3940000000038708\n",
      "83 :  0.4249999999992724\n",
      "84 :  0.4350000000013097\n",
      "85 :  0.3705000000045402\n",
      "86 :  0.40399999999499414\n",
      "87 :  0.4470000000001164\n",
      "88 :  0.37149999999746797\n",
      "89 :  0.35749999999825377\n",
      "90 :  0.38000000000101863\n",
      "91 :  0.3949999999967986\n",
      "92 :  0.419000000001688\n",
      "93 :  0.41099999999278225\n",
      "94 :  0.3819999999977881\n",
      "95 :  0.3790000000008149\n",
      "96 :  0.4739999999983411\n",
      "97 :  0.4179999999978463\n",
      "98 :  0.5160000000032596\n",
      "99 :  0.3864999999968859\n",
      "100 :  0.3890000000010332\n",
      "101 :  0.39350000000194996\n",
      "102 :  0.43400000000110595\n",
      "103 :  0.4099999999998545\n",
      "104 :  0.43400000000110595\n",
      "105 :  0.49100000000180444\n",
      "106 :  0.40799999999580905\n",
      "107 :  0.42599999999947613\n",
      "108 :  0.4099999999962165\n",
      "109 :  0.35300000000279397\n",
      "110 :  0.3709999999991851\n",
      "111 :  0.44900000000052387\n",
      "112 :  0.385999999998603\n",
      "113 :  0.41199999999662396\n",
      "114 :  0.6805000000003929\n",
      "115 :  0.36700000000200816\n",
      "116 :  0.4054999999971187\n",
      "117 :  0.36999999999898137\n",
      "118 :  0.42950000000200816\n",
      "119 :  0.43149999999877764\n",
      "120 :  0.38699999999516876\n",
      "121 :  0.3150000000023283\n",
      "122 :  0.37000000000261934\n",
      "123 :  0.49500000000261934\n",
      "124 :  0.4169999999940046\n",
      "125 :  0.45600000000558794\n",
      "126 :  0.4059999999990396\n",
      "127 :  0.40499999999701686\n",
      "128 :  0.4059999999990396\n",
      "129 :  0.40499999999883585\n",
      "130 :  0.37400000000343425\n",
      "131 :  0.4110000000000582\n",
      "132 :  0.38100000000122236\n",
      "133 :  0.3815000000013242\n",
      "134 :  0.4650000000001455\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hm = [1.5,3,4.5,6,7.5]\n",
    "hc = [0.5,0.37,0.25]\n",
    "\n",
    "itr = [2,4,6]\n",
    "ht = [1.7,2.5,3.5]\n",
    "\n",
    "print(hm)\n",
    "print(hc)\n",
    "print(itr)\n",
    "Xf =np.empty((1,1))\n",
    "Yf =np.empty((1,1))\n",
    "Zf =np.empty((1,1))\n",
    "Wf = np.empty((1,len(itr)))\n",
    "num_f = np.empty((1,len(itr)))\n",
    "Xcntrd = []\n",
    "Ycntrd = []\n",
    "# x = arr[:,0]\n",
    "# y = arr[:,1]\n",
    "# z = arr[:,2]\n",
    "x=arr[:,0]\n",
    "y=arr[:,1]\n",
    "z=arr[:,2]\n",
    "xmin, xmax = np.min(x), np.max(x)\n",
    "ymin, ymax = np.min(y), np.max(y)\n",
    "z = z.reshape(-1,1)\n",
    "\n",
    "\n",
    "w,h = np.abs(xmax-xmin), np.abs(ymax-ymin)\n",
    "print(h,w)\n",
    "\n",
    "hmargin = 0\n",
    "wmargin = 0\n",
    "# hstep = h/200\n",
    "# wstep = w/200\n",
    "\n",
    "hstep = 10\n",
    "wstep = 10\n",
    "\n",
    "ar1= (np.arange(ymin,ymax+1,hstep))\n",
    "ar1 = ar1[:-1]\n",
    "#print(ar1)\n",
    "ar2= np.arange(xmin,xmax+1,wstep)\n",
    "ar2 = ar2[:-1]\n",
    "#print(ar2)\n",
    "\n",
    "ar1 = list(ar1.ravel())\n",
    "ar2 = list(ar2.ravel())\n",
    "\n",
    "label = np.empty((len(x),1))\n",
    "label = label.astype(np.uint8)\n",
    "k=0\n",
    "for id in ar1:\n",
    "    for di in ar2:\n",
    "        label[(x>=di)&(x<=di+wstep)&(y>=id)&(y <= id + hstep)] = k\n",
    "        k+=1\n",
    "print('initial label added based on grid')\n",
    "del k\n",
    "num_tree = len(np.unique(label))\n",
    "# tree_H = np.empty(k, dtype = np.float32)\n",
    "tree_H = np.empty(num_tree, dtype = np.float32)\n",
    "print(label.shape,z.shape,num_tree,tree_H.shape)\n",
    "for lbl in list(np.unique(label)):\n",
    "    tree_H[lbl] = np.max(z[label == lbl]) - np.min(z[label == lbl])\n",
    "print('height computed for each sub grid')\n",
    "print(np.min(tree_H), np.max(tree_H),np.median(tree_H))  \n",
    "\n",
    "DBH = []   \n",
    "z = z.reshape(-1,)\n",
    "label = label.reshape(-1,)\n",
    "i = 0\n",
    "for mh in hm:\n",
    "    for ch in hc:\n",
    "        \n",
    "        X_sub,Y_sub,Z_sub,l_sub = sub_set(x,y, z,label,mh,ch)\n",
    "        for th in ht: \n",
    "            label2,cent2,out2,c_dist2 = apply_birch(pd.DataFrame({'x':X_sub.ravel(), 'y':Y_sub.ravel()}),th)\n",
    "            wf = np.empty((len(cent2),len(itr)))\n",
    "            n_f = np.empty((len(cent2),len(itr)))\n",
    "            j = 0\n",
    "            for rti in itr: \n",
    "                X_sub2, Y_sub2, Z_sub2, R_sub2, l_sub2 = ad_buffer(X_sub, Y_sub, Z_sub, c_dist2, label2,k_max=rti)\n",
    "                \n",
    "                X_sub2, Y_sub2, Z_sub2, R_sub2, l_sub2 = apply_zr(X_sub2, Y_sub2, Z_sub2, R_sub2, l_sub2, it_max = rti)\n",
    "                \n",
    "                X_sub2, Y_sub2, Z_sub2, R_sub2, l_sub2 = apply_finder(X_sub2, Y_sub2, Z_sub2, R_sub2, l_sub2, itmax = rti)\n",
    "                \n",
    "                w,dbh = width_finder(X_sub2, Y_sub2, Z_sub2, l_sub2)\n",
    "                DBH.append(dbh)\n",
    "                print(i,': ',dbh)\n",
    "                # a1, a2 = np.unique(l_sub, return_counts=True)\n",
    "                # a1 = a1.astype(np.uint8)\n",
    "                \n",
    "                # wf[a1,j] = w[:,0]\n",
    "                # n_f[a1,j] = a2\n",
    "                \n",
    "                \n",
    "                Xf = np.concatenate((Xf,X_sub))\n",
    "                Yf = np.concatenate((Yf,Y_sub))\n",
    "                Zf = np.concatenate((Zf,Z_sub))\n",
    "                # Wf = np.concatenate((Wf,wf))\n",
    "                # num_f = np.concatenate((num_f,n_f))\n",
    "                #Xcntrd.append(np.average(X_sub4))\n",
    "                #Ycntrd.append(np.average(Y_sub4))\n",
    "                i+=1\n",
    "                j+=1\n",
    "            #print('Wf: ',Wf.shape, num_f.shape)\n",
    "Xf = (Xf).reshape(-1,1)\n",
    "Yf = (Yf).reshape(-1,1)\n",
    "Zf = (Zf).reshape(-1,1)\n",
    "# Wf = (Wf).reshape(-1,len(itr))\n",
    "# num_f = (num_f).reshape(-1,len(itr))\n",
    "\n",
    "Xf = Xf[1:,:]\n",
    "Yf = Yf[1:,:]\n",
    "Zf = Zf[1:,:]\n",
    "# Wf = Wf[1:,:]\n",
    "# num_f = num_f[1:,:]\n",
    "\n",
    "final_dbh = np.median(np.array(DBH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2J9sGojyeU0",
    "outputId": "6225618a-29d8-438f-d13c-b027271835a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(tree_H[tree_H>300]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "oNI5qgfDJEm6"
   },
   "outputs": [],
   "source": [
    "# dataset = pd.DataFrame({'Column1': X_sub[:,0], 'Column2': Y_sub[:,0],'Column3': Z_sub[:,0], 'Column4': label2})\n",
    "# dataset.to_csv('/content/drive/My Drive/Excel/lidar/test_data/grid3_subset_output.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "GjEf0HySLiGS"
   },
   "outputs": [],
   "source": [
    "# dataset = pd.DataFrame({'Column1': X_sub2[:,0], 'Column2': Y_sub2[:,0],'Column3': Z_sub2[:,0], 'Column4': l_sub2[:,0]})\n",
    "# dataset.to_csv('/content/drive/My Drive/Excel/lidar/test_data/grid3_buffer_output.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "kCCmnFclM68E"
   },
   "outputs": [],
   "source": [
    "# dataset = pd.DataFrame({'Column1': X_sub3[:,0], 'Column2': Y_sub3[:,0],'Column3': Z_sub3[:,0], 'Column4': l_sub3[:,0]})\n",
    "# dataset.to_csv('/content/drive/My Drive/Excel/lidar/test_data/grid3_zr_adjust_output.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "Ji2_sMbWNHrw"
   },
   "outputs": [],
   "source": [
    "# dataset = pd.DataFrame({'Column1': X_sub4[:,0], 'Column2': Y_sub4[:,0],'Column3': Z_sub4[:,0], 'Column4': l_sub4[:,0]})\n",
    "# dataset.to_csv('/content/drive/My Drive/Excel/lidar/test_data/grid3_xyfinder_output.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "hDdOHzSDuEnF"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-198-65873ea81497>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabel_3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcent_3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout_3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc_dist_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_birch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mXf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mYf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcent_3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-172-4276d273c253>\u001b[0m in \u001b[0;36mapply_birch\u001b[1;34m(df, th)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mbrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBirch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbranching_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mbrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\cluster\\birch.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \"\"\"\n\u001b[0;32m    446\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\cluster\\birch.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miter_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[0msubcluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_CFSubcluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear_sum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m             \u001b[0msplit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert_cf_subcluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubcluster\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\cluster\\birch.py\u001b[0m in \u001b[0;36minsert_cf_subcluster\u001b[1;34m(self, subcluster)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;31m# We need to find the closest subcluster among all the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;31m# subclusters so that we can insert our new subcluster.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mdist_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcentroids_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcentroid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m         \u001b[0mdist_matrix\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0mdist_matrix\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquared_norm_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "label_3,cent_3,out_3,c_dist_3 = apply_birch(pd.DataFrame({'x':Xf.ravel(), 'y':Yf.ravel()}),2.5)\n",
    "print(len(cent_3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3FrdWvwhPvOH"
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'Column1': Xf[:,0], 'Column2': Yf[:,0],'Column3': Zf[:,0], 'Column4': label_3})\n",
    "dataset.to_csv('./grid3_after_birch_output.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rco0yxWmqdH"
   },
   "outputs": [],
   "source": [
    "print(len(np.unique(label_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2Tn2dCVmqdK"
   },
   "outputs": [],
   "source": [
    "label3,cent3,out3,c_dist3 = apply_kmeans(pd.DataFrame({'x':Xf.ravel(), 'y':Yf.ravel()}),len(np.unique(label_3)),'k-means++')\n",
    "print(len(cent3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AA_KOEvxUDO9"
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'Column1': Xf[:,0], 'Column2': Yf[:,0],'Column3': Zf[:,0], 'Column4': out3})\n",
    "dataset.to_csv('./grid3_after_kmeans_output2.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRLBrTbSy-Q6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_kmeans(Xf,Yf,Zf,label3,cent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNSnloZJrsCu"
   },
   "outputs": [],
   "source": [
    "w = final_dbh*np.ones((len(cent3),1))\n",
    "print(w.shape)\n",
    "X_f = np.empty((1,1))\n",
    "Y_f = np.empty((1,1))\n",
    "Z_f = np.empty((1,1))\n",
    "R_f = np.empty((1,1))\n",
    "l_f = np.empty((1,1))\n",
    "\n",
    "for lbl in list(np.unique(out3)):\n",
    "\n",
    "    x1,y1,z1,r1,l1 = Xf[out3 == lbl], Yf[out3 == lbl], Zf[out3 == lbl], c_dist3[out3 == lbl], out3[out3 == lbl]\n",
    "    \n",
    "    x2 = x1[r1<=w[lbl]/2]\n",
    "    y2 = y1[r1<=w[lbl]/2]\n",
    "    z2 = z1[r1<=w[lbl]/2]\n",
    "    l2 = l1[r1<=w[lbl]/2]\n",
    "    r2 = r1[r1<=w[lbl]/2]\n",
    "\n",
    "    \n",
    "    x2 = x2.reshape(-1,1)\n",
    "    y2 = y2.reshape(-1,1)\n",
    "    z2 = z2.reshape(-1,1)\n",
    "    r2 = r2.reshape(-1,1)\n",
    "    l2 = l2.reshape(-1,1)\n",
    "    \n",
    "    \n",
    "    print(len(l2))\n",
    "\n",
    "    X_f = np.concatenate((X_f,x2))\n",
    "    Y_f = np.concatenate((Y_f,y2))\n",
    "    Z_f = np.concatenate((Z_f,z2))\n",
    "    R_f = np.concatenate((R_f,r2))    \n",
    "    l_f = np.concatenate((l_f,l2))\n",
    "X_f = (X_f).reshape(-1,1)\n",
    "Y_f = (Y_f).reshape(-1,1)\n",
    "Z_f = (Z_f).reshape(-1,1)\n",
    "R_f = (R_f).reshape(-1,1)\n",
    "l_f = (l_f).reshape(-1,1)\n",
    "\n",
    "X_f = X_f[1:,:]\n",
    "Y_f = Y_f[1:,:]\n",
    "Z_f = Z_f[1:,:]\n",
    "R_f = R_f[1:,:]\n",
    "l_f = l_f[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18jgMA1enuR4"
   },
   "outputs": [],
   "source": [
    "clabel_3 = []\n",
    "#clabel_3 = list(map(''.join, zip('cl_', label_3.astype(str))))\n",
    "#clabel_3 = 'cl_' + str(label_3) \n",
    "\n",
    "for lbl in list(l_f):\n",
    "    clabel_3.append('cl_' + str(lbl+1))\n",
    "print(clabel_3[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zl9AQ8wk2Rn"
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'Column1': X_f[:,0], 'Column2': Y_f[:,0],'Column3': Z_f[:,0], 'Column4': l_f[:,0]})\n",
    "dataset.to_csv('./grid3_before_outlier_output.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7f22MJqByq8"
   },
   "outputs": [],
   "source": [
    "w1,dbh = width_finder(X_f,Y_f,Z_f,l_f)\n",
    "            \n",
    "l_list = list((np.unique(l_f)).astype(np.uint8).reshape(-1,1))\n",
    "print(len(l_list))\n",
    "centr = np.empty((len(l_list),5), dtype = np.float32)\n",
    "\n",
    "print(w1.shape,l_list[5])\n",
    "i = 0\n",
    "for k,lbl in enumerate(l_list):\n",
    "\n",
    "    x1,y1,z1,r1,l1 = X_f[l_f == lbl], Y_f[l_f == lbl], Z_f[l_f == lbl], R_f[l_f == lbl], l_f[l_f == lbl]\n",
    "    if len(z1) >1:\n",
    "        centr[i,0] = np.average(x1)\n",
    "        centr[i,1] = np.average(y1)\n",
    "        centr[i,2] = np.max(z1)\n",
    "        centr[i,3] = w1[k]\n",
    "        centr[i,4] = (l_list[i]+1)\n",
    "    print(centr[i,:])\n",
    "    i += 1\n",
    "\n",
    "\n",
    "#print(len(centr))\n",
    "#dataset = pd.DataFrame(centr)\n",
    "#dataset.to_csv('./ldr_full_b14_centre.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtqEZRoGTb_O"
   },
   "outputs": [],
   "source": [
    "X_f2 = np.empty((1,1))\n",
    "Y_f2 = np.empty((1,1))\n",
    "Z_f2 = np.empty((1,1))\n",
    "R_f2 = np.empty((1,1))\n",
    "l_f2 = np.empty((1,1))\n",
    "\n",
    "\n",
    "for lbl in list(np.unique(l_f)):\n",
    "\n",
    "    x1,y1,z1,r1,l1 = X_f[l_f == lbl], Y_f[l_f == lbl], Z_f[l_f == lbl], R_f[l_f == lbl], l_f[l_f == lbl]\n",
    "    \n",
    "    length2 = len(l1)\n",
    "    centr2 = np.empty((length2,5), dtype = np.float32)\n",
    "\n",
    "    centr2[:,0] = x1.reshape(-1,)\n",
    "    centr2[:,1] = y1.reshape(-1,)\n",
    "    centr2[:,2] = z1.reshape(-1,)\n",
    "    centr2[:,3] = r1.reshape(-1,)\n",
    "    centr2[:,4] = l1.reshape(-1,)\n",
    "    \n",
    "    \n",
    "    #print(centr[lbl,:])\n",
    "    print(length2)\n",
    "    dataset = pd.DataFrame(centr2)\n",
    "    #dataset1 = dataset[(np.abs(stats.zscore(dataset.iloc[:,3:4])) < 1.96).all(axis=1)]\n",
    "    dataset1 = dataset[(stats.zscore(dataset.iloc[:,3:4]) < 1.96).all(axis=1)]\n",
    "    dataset2 = dataset1[(np.abs(stats.zscore(dataset1.iloc[:,2:3])) < 1.96).all(axis=1)]\n",
    "    \n",
    "    x2 = dataset2.iloc[:,0]\n",
    "    y2 = dataset2.iloc[:,1]\n",
    "    z2 = dataset2.iloc[:,2]\n",
    "    r2 = dataset2.iloc[:,3]\n",
    "    l2 = dataset2.iloc[:,4]\n",
    "\n",
    "    x2 = np.array(x2).reshape(-1,1)\n",
    "    y2 = np.array(y2).reshape(-1,1)\n",
    "    z2 = np.array(z2).reshape(-1,1)\n",
    "    r2 = np.array(r2).reshape(-1,1)\n",
    "    l2 = np.array(l2).reshape(-1,1)\n",
    "    \n",
    "    print(len(l2))\n",
    "\n",
    "    X_f2 = np.concatenate((X_f2,x2))\n",
    "    Y_f2 = np.concatenate((Y_f2,y2))\n",
    "    Z_f2 = np.concatenate((Z_f2,z2))\n",
    "    R_f2 = np.concatenate((R_f2,r2))    \n",
    "    l_f2 = np.concatenate((l_f2,l2))\n",
    "X_f2 = (X_f2).reshape(-1,1)\n",
    "Y_f2 = (Y_f2).reshape(-1,1)\n",
    "Z_f2 = (Z_f2).reshape(-1,1)\n",
    "R_f2 = (R_f2).reshape(-1,1)\n",
    "l_f2 = (l_f2).reshape(-1,1)\n",
    "\n",
    "X_f2 = X_f2[1:,:]\n",
    "Y_f2 = Y_f2[1:,:]\n",
    "Z_f2 = Z_f2[1:,:]\n",
    "R_f2 = R_f2[1:,:]\n",
    "l_f2 = l_f2[1:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsCtNxHheoZW"
   },
   "outputs": [],
   "source": [
    "w,dbh = width_finder(X_f2,Y_f2,Z_f2,l_f2)\n",
    "            \n",
    "l_list = list((np.unique(l_f2)).astype(np.uint8).reshape(-1,1))\n",
    "centr = np.empty((len(l_list),5), dtype = np.float32)\n",
    "\n",
    "i = 0\n",
    "for k,lbl in enumerate(l_list):\n",
    "    x1,y1,z1,r1,l1 = X_f2[l_f2 == lbl], Y_f2[l_f2 == lbl], Z_f2[l_f2 == lbl], R_f2[l_f2 == lbl], l_f2[l_f2 == lbl]\n",
    "    \n",
    "    print(w.shape,len(l_list),l_list[i])\n",
    "    if len(z1) >1:\n",
    "        centr[i,0] = np.average(x1)\n",
    "        centr[i,1] = np.average(y1)\n",
    "        centr[i,2] = np.max(z1)\n",
    "        centr[i,3] = w[k]\n",
    "        centr[i,4] = (l_list[i]+1)\n",
    "    print(centr[i,:])\n",
    "    i += 1   \n",
    "    \n",
    "#print(len(centr))\n",
    "#dataset = pd.DataFrame(centr)\n",
    "#dataset.to_csv('./ldr_full_b14_out_centre.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSraIbOtm_zb"
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'Column1': X_f2[:,0], 'Column2': Y_f2[:,0],'Column3': Z_f2[:,0], 'Column4': l_f2[:,0]})\n",
    "dataset.to_csv('./grid3_outlier1_output.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Jv7MlAvee8J"
   },
   "outputs": [],
   "source": [
    "X_f3 = np.empty((1,1))\n",
    "Y_f3 = np.empty((1,1))\n",
    "Z_f3 = np.empty((1,1))\n",
    "R_f3 = np.empty((1,1))\n",
    "l_f3 = np.empty((1,1))\n",
    "\n",
    "a1,a2 = np.unique(l_f2,return_counts = True)\n",
    "darr = np.empty((len(a1),2))\n",
    "darr[:,0] = a1\n",
    "darr[:,1] = a2\n",
    "df3 = pd.DataFrame(darr)\n",
    "\n",
    "df4 = df3[(df3.iloc[:,1:] > 30).all(axis=1)]\n",
    "\n",
    "a11 = (df4.iloc[:,0])\n",
    "print(len(darr))\n",
    "print(len(a11))\n",
    "for lbl in list(a11):\n",
    "    x2,y2,z2,r2,l2 = X_f2[l_f2 == lbl], Y_f2[l_f2 == lbl], Z_f2[l_f2 == lbl], R_f2[l_f2 == lbl], l_f2[l_f2 == lbl]\n",
    "    \n",
    "    x2 = np.array(x2).reshape(-1,1)\n",
    "    y2 = np.array(y2).reshape(-1,1)\n",
    "    z2 = np.array(z2).reshape(-1,1)\n",
    "    r2 = np.array(r2).reshape(-1,1)\n",
    "    l2 = np.array(l2).reshape(-1,1)\n",
    "    \n",
    "    print(len(l2))\n",
    "\n",
    "    X_f3 = np.concatenate((X_f3,x2))\n",
    "    Y_f3 = np.concatenate((Y_f3,y2))\n",
    "    Z_f3 = np.concatenate((Z_f3,z2))\n",
    "    R_f3 = np.concatenate((R_f3,r2))    \n",
    "    l_f3 = np.concatenate((l_f3,l2))\n",
    "X_f3 = (X_f3).reshape(-1,1)\n",
    "Y_f3 = (Y_f3).reshape(-1,1)\n",
    "Z_f3 = (Z_f3).reshape(-1,1)\n",
    "R_f3 = (R_f3).reshape(-1,1)\n",
    "l_f3 = (l_f3).reshape(-1,1)\n",
    "\n",
    "X_f3 = X_f3[1:,:]\n",
    "Y_f3 = Y_f3[1:,:]\n",
    "Z_f3 = Z_f3[1:,:]\n",
    "R_f3 = R_f3[1:,:]\n",
    "l_f3 = l_f3[1:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0iIkLlcXYa_T"
   },
   "outputs": [],
   "source": [
    "w,dbh = width_finder(X_f3,Y_f3,Z_f3,l_f3)\n",
    "            \n",
    "l_list = list((np.unique(l_f3)).astype(np.uint8).reshape(-1,1))\n",
    "centr = np.empty((len(l_list),5), dtype = np.float32)\n",
    "\n",
    "i = 0\n",
    "for k,lbl in enumerate(l_list):\n",
    "    x1,y1,z1,r1,l1 = X_f3[l_f3 == lbl], Y_f3[l_f3 == lbl], Z_f3[l_f3 == lbl], R_f3[l_f3 == lbl], l_f3[l_f3 == lbl]\n",
    "    \n",
    "    print(w.shape,len(l_list),l_list[i])\n",
    "    if len(z1) >1:\n",
    "        centr[i,0] = np.average(x1)\n",
    "        centr[i,1] = np.average(y1)\n",
    "        centr[i,2] = np.max(z1)\n",
    "        centr[i,3] = w[k]\n",
    "        centr[i,4] = (l_list[i]+1)\n",
    "    print(centr[i,:])\n",
    "    i += 1   \n",
    "    \n",
    "#print(len(centr))\n",
    "#dataset = pd.DataFrame(centr)\n",
    "#dataset.to_csv('./ldr_full_b14_out2__centre.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCd68jOQpwX8"
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'Column1': X_f3[:,0], 'Column2': Y_f3[:,0],'Column3': Z_f3[:,0], 'Column4': l_f3[:,0]})\n",
    "dataset.to_csv('./grid3_outlier2_output.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wtRSxhnQy5_"
   },
   "outputs": [],
   "source": [
    "X_f4 = np.empty((1,1))\n",
    "Y_f4 = np.empty((1,1))\n",
    "Z_f4 = np.empty((1,1))\n",
    "R_f4 = np.empty((1,1))\n",
    "l_f4 = np.empty((1,1))\n",
    "n_f4 = np.empty((1,1))\n",
    "\n",
    "for lbl in list(np.unique(l_f3)):\n",
    "\n",
    "    x1,y1,z1,r1,l1 = X_f[l_f == lbl], Y_f[l_f == lbl], Z_f[l_f == lbl], R_f[l_f == lbl], l_f[l_f == lbl]\n",
    "    darr2 = np.empty((len(x1),5))\n",
    "    darr2[:,0] = x1\n",
    "    darr2[:,1] = y1\n",
    "    darr2[:,2] = z1\n",
    "    darr2[:,3] = r1\n",
    "    darr2[:,4] = l1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    a1,a2 = np.unique(darr2,return_counts = True, axis = 0)\n",
    "    \n",
    "    x2 = np.array(a1[:,0]).reshape(-1,1)\n",
    "    y2 = np.array(a1[:,1]).reshape(-1,1)\n",
    "    z2 = np.array(a1[:,2]).reshape(-1,1)\n",
    "    r2 = np.array(a1[:,3]).reshape(-1,1)\n",
    "    l2 = np.array(a1[:,4]).reshape(-1,1)\n",
    "    a2 = a2.reshape(-1,1)\n",
    "    #print(len(a2))\n",
    "\n",
    "    X_f4 = np.concatenate((X_f4,x2))\n",
    "    Y_f4 = np.concatenate((Y_f4,y2))\n",
    "    Z_f4 = np.concatenate((Z_f4,z2))\n",
    "    R_f4 = np.concatenate((R_f4,r2))    \n",
    "    l_f4 = np.concatenate((l_f4,l2))\n",
    "    n_f4 = np.concatenate((n_f4,a2))    \n",
    "    \n",
    "X_f4 = (X_f4).reshape(-1,1)\n",
    "Y_f4 = (Y_f4).reshape(-1,1)\n",
    "Z_f4 = (Z_f4).reshape(-1,1)\n",
    "R_f4 = (R_f4).reshape(-1,1)\n",
    "l_f4 = (l_f4).reshape(-1,1)\n",
    "n_f4 = (n_f4).reshape(-1,1)\n",
    "\n",
    "X_f4 = X_f4[1:,:]\n",
    "Y_f4 = Y_f4[1:,:]\n",
    "Z_f4 = Z_f4[1:,:]\n",
    "R_f4 = R_f4[1:,:]\n",
    "l_f4 = l_f4[1:,:]\n",
    "n_f4 = n_f4[1:,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_WuE7zbvqIR2"
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'Column1': X_f4[:,0], 'Column2': Y_f4[:,0],'Column3': Z_f4[:,0], 'Column4': l_f4[:,0]})\n",
    "dataset.to_csv('./grid3_unique_pts_output.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ECO7wwkeV_2"
   },
   "outputs": [],
   "source": [
    "X_f5 = np.empty((1,1))\n",
    "Y_f5 = np.empty((1,1))\n",
    "Z_f5 = np.empty((1,1))\n",
    "R_f5 = np.empty((1,1))\n",
    "l_f5 = np.empty((1,1))\n",
    "\n",
    "for lbl in list(np.unique(l_f4)):\n",
    "    \n",
    "    x1,y1,z1,r1,l1 = X_f4[l_f4 == lbl], Y_f4[l_f4 == lbl], Z_f4[l_f4 == lbl], R_f4[l_f4 == lbl], l_f4[l_f4 == lbl]\n",
    "    \n",
    "    length2 = len(l1)\n",
    "    centr2 = np.empty((length2,5), dtype = np.float32)\n",
    "\n",
    "    centr2[:,0] = x1.reshape(-1,)\n",
    "    centr2[:,1] = y1.reshape(-1,)\n",
    "    centr2[:,2] = z1.reshape(-1,)\n",
    "    centr2[:,3] = r1.reshape(-1,)\n",
    "    centr2[:,4] = l1.reshape(-1,)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(length2)\n",
    "    dataset = pd.DataFrame(centr2)\n",
    "    \n",
    "    dataset1 = dataset[(stats.zscore(dataset.iloc[:,3:4]) < 1.96).all(axis=1)]\n",
    "    dataset2 = dataset1[(np.abs(stats.zscore(dataset1.iloc[:,2:3])) < 1.96).all(axis=1)]\n",
    "    \n",
    "    x2 = dataset2.iloc[:,0]\n",
    "    y2 = dataset2.iloc[:,1]\n",
    "    z2 = dataset2.iloc[:,2]\n",
    "    r2 = dataset2.iloc[:,3]\n",
    "    l2 = dataset2.iloc[:,4]\n",
    "\n",
    "    x2 = np.array(x2).reshape(-1,1)\n",
    "    y2 = np.array(y2).reshape(-1,1)\n",
    "    z2 = np.array(z2).reshape(-1,1)\n",
    "    r2 = np.array(r2).reshape(-1,1)\n",
    "    l2 = np.array(l2).reshape(-1,1)\n",
    "    \n",
    "    print(len(l2))\n",
    "\n",
    "    X_f5 = np.concatenate((X_f5,x2))\n",
    "    Y_f5 = np.concatenate((Y_f5,y2))\n",
    "    Z_f5 = np.concatenate((Z_f5,z2))\n",
    "    R_f5 = np.concatenate((R_f5,r2))    \n",
    "    l_f5 = np.concatenate((l_f5,l2))\n",
    "X_f5 = (X_f5).reshape(-1,1)\n",
    "Y_f5 = (Y_f5).reshape(-1,1)\n",
    "Z_f5 = (Z_f5).reshape(-1,1)\n",
    "R_f5 = (R_f5).reshape(-1,1)\n",
    "l_f5 = (l_f5).reshape(-1,1)\n",
    "\n",
    "X_f5 = X_f5[1:,:]\n",
    "Y_f5 = Y_f5[1:,:]\n",
    "Z_f5 = Z_f5[1:,:]\n",
    "R_f5 = R_f5[1:,:]\n",
    "l_f5 = l_f5[1:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmWQ72dHqZoq"
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'Column1': X_f5[:,0], 'Column2': Y_f5[:,0],'Column3': Z_f5[:,0], 'Column4': l_f5[:,0]})\n",
    "dataset.to_csv('./grid3_outlier3_unique_pts_output.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48NF36WHgTmF"
   },
   "outputs": [],
   "source": [
    "X_f6 = np.empty((1,1))\n",
    "Y_f6 = np.empty((1,1))\n",
    "Z_f6 = np.empty((1,1))\n",
    "R_f6 = np.empty((1,1))\n",
    "l_f6 = np.empty((1,1))\n",
    "\n",
    "\n",
    "a1,a2 = np.unique(l_f5,return_counts = True)\n",
    "darr = np.empty((len(a1),2))\n",
    "darr[:,0] = a1\n",
    "darr[:,1] = a2\n",
    "df3 = pd.DataFrame(darr)\n",
    "\n",
    "# df4 = df3[(df3.iloc[:,1:] > 30).all(axis=1)]\n",
    "\n",
    "# a11 = (df4.iloc[:,0])\n",
    "a11 = (df3.iloc[:,0])\n",
    "print(len(darr))\n",
    "print(len(a11))\n",
    "for lbl in list(a11):\n",
    "    x2,y2,z2,r2,l2 = X_f5[l_f5 == lbl], Y_f5[l_f5 == lbl], Z_f5[l_f5 == lbl], R_f5[l_f5 == lbl], l_f5[l_f5 == lbl]\n",
    "    \n",
    "    x2 = np.array(x2).reshape(-1,1)\n",
    "    y2 = np.array(y2).reshape(-1,1)\n",
    "    z2 = np.array(z2).reshape(-1,1)\n",
    "    r2 = np.array(r2).reshape(-1,1)\n",
    "    l2 = np.array(l2).reshape(-1,1)\n",
    "    \n",
    "    print(len(l2))\n",
    "\n",
    "    X_f6 = np.concatenate((X_f6,x2))\n",
    "    Y_f6 = np.concatenate((Y_f6,y2))\n",
    "    Z_f6 = np.concatenate((Z_f6,z2))\n",
    "    R_f6 = np.concatenate((R_f6,r2))    \n",
    "    l_f6 = np.concatenate((l_f6,l2))\n",
    "X_f6 = (X_f6).reshape(-1,1)\n",
    "Y_f6 = (Y_f6).reshape(-1,1)\n",
    "Z_f6 = (Z_f6).reshape(-1,1)\n",
    "R_f6 = (R_f6).reshape(-1,1)\n",
    "l_f6 = (l_f6).reshape(-1,1)\n",
    "\n",
    "X_f6 = X_f6[1:,:]\n",
    "Y_f6 = Y_f6[1:,:]\n",
    "Z_f6 = Z_f6[1:,:]\n",
    "R_f6 = R_f6[1:,:]\n",
    "l_f6 = l_f6[1:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPgOvwCIq85q"
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'Column1': X_f6[:,0], 'Column2': Y_f6[:,0],'Column3': Z_f6[:,0], 'Column4': l_f6[:,0]})\n",
    "dataset.to_csv('./grid3_outlier4_unique_pts_output.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04We6tJ1jbXA"
   },
   "outputs": [],
   "source": [
    "w,dbh = width_finder(X_f6,Y_f6,Z_f6,l_f6)\n",
    "            \n",
    "l_list = list((np.unique(l_f6)).astype(np.uint8).reshape(-1,1))\n",
    "centr = np.empty((len(l_list),5), dtype = np.float32)\n",
    "\n",
    "i = 0\n",
    "for k,lbl in enumerate(l_list):\n",
    "    x1,y1,z1,r1,l1 = X_f6[l_f6 == lbl], Y_f6[l_f6 == lbl], Z_f6[l_f6 == lbl], R_f6[l_f6 == lbl], l_f6[l_f6 == lbl]\n",
    "\n",
    "    print(w.shape,len(l_list),l_list[i])\n",
    "    if len(z1) >1:\n",
    "        centr[i,0] = np.average(x1)\n",
    "        centr[i,1] = np.average(y1)\n",
    "        centr[i,2] = np.max(z1)\n",
    "        centr[i,3] = w[k]\n",
    "        centr[i,4] = (l_list[i]+1)\n",
    "    print(centr[i,:])\n",
    "    i += 1   \n",
    "    \n",
    "#print(len(centr))\n",
    "#dataset = pd.DataFrame(centr)\n",
    "#dataset.to_csv('./ldr_full_b14_out4__centre.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFgh2FRlGZcX"
   },
   "outputs": [],
   "source": [
    "X_f7 = np.empty((1,1))\n",
    "Y_f7 = np.empty((1,1))\n",
    "Z_f7 = np.empty((1,1))\n",
    "R_f7 = np.empty((1,1))\n",
    "l_f7 = np.empty((1,1))\n",
    "\n",
    "\n",
    "for lbl in list(np.unique(l_f6)):\n",
    "    x1,y1,z1,r1,l1 = X_f6[l_f6 == lbl], Y_f6[l_f6 == lbl], Z_f6[l_f6 == lbl], R_f6[l_f6 == lbl], l_f6[l_f6 == lbl]\n",
    "\n",
    "    xmax,xmin = np.max(x1), np.min(x1)\n",
    "    ymax,ymin = np.max(y1), np.min(y1)\n",
    "    zmin = np.min(Z[(X<=xmax) & (X>=xmin) & (Y<=ymax) & (Y>=ymin)]) + 5\n",
    "    zmax = zmin + 10\n",
    "    \n",
    "    x2 = x1[(z1<=zmax) & (z1>=zmin)]\n",
    "    y2 = y1[(z1<=zmax) & (z1>=zmin)]\n",
    "    z2 = z1[(z1<=zmax) & (z1>=zmin)]\n",
    "    r2 = r1[(z1<=zmax) & (z1>=zmin)]\n",
    "    l2 = l1[(z1<=zmax) & (z1>=zmin)]\n",
    "    \n",
    "    x2 = np.array(x2).reshape(-1,1)\n",
    "    y2 = np.array(y2).reshape(-1,1)\n",
    "    z2 = np.array(z2).reshape(-1,1)\n",
    "    r2 = np.array(r2).reshape(-1,1)\n",
    "    l2 = np.array(l2).reshape(-1,1)\n",
    "    \n",
    "    print(len(l2))\n",
    "\n",
    "    X_f7 = np.concatenate((X_f7,x2))\n",
    "    Y_f7 = np.concatenate((Y_f7,y2))\n",
    "    Z_f7 = np.concatenate((Z_f7,z2))\n",
    "    R_f7 = np.concatenate((R_f7,r2))    \n",
    "    l_f7 = np.concatenate((l_f7,l2))\n",
    "X_f7 = (X_f7).reshape(-1,1)\n",
    "Y_f7 = (Y_f7).reshape(-1,1)\n",
    "Z_f7 = (Z_f7).reshape(-1,1)\n",
    "R_f7 = (R_f7).reshape(-1,1)\n",
    "l_f7 = (l_f7).reshape(-1,1)\n",
    "\n",
    "X_f7 = X_f7[1:,:]\n",
    "Y_f7 = Y_f7[1:,:]\n",
    "Z_f7 = Z_f7[1:,:]\n",
    "R_f7 = R_f7[1:,:]\n",
    "l_f7 = l_f7[1:,:]                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7293g-9Ii4Ko"
   },
   "outputs": [],
   "source": [
    "print(len(R_f7), len(l_f7), len(X_f7),len(Y_f7), len(Z_f7))\n",
    "dataset = pd.DataFrame({'Column1': X_f7[:,0], 'Column2': Y_f7[:,0],'Column3': Z_f7[:,0], 'Column4': R_f7[:,0],'Column5': l_f7[:,0]})\n",
    "dataset.to_csv('./grid3_height_subset_unique_pts_output.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXvu6rwEjfLW"
   },
   "outputs": [],
   "source": [
    "w,dbh = width_finder(X_f7,Y_f7,Z_f7,l_f7)\n",
    "            \n",
    "l_list = list((np.unique(l_f7)).astype(np.uint8).reshape(-1,1))\n",
    "centr = np.empty((len(l_list),5), dtype = np.float32)\n",
    "\n",
    "i = 0\n",
    "for k,lbl in enumerate(l_list):\n",
    "    x1,y1,z1,r1,l1 = X_f7[l_f7 == lbl], Y_f7[l_f7 == lbl], Z_f7[l_f7 == lbl], R_f7[l_f7 == lbl], l_f7[l_f7 == lbl]\n",
    "\n",
    "    print(w.shape,len(l_list),l_list[i])\n",
    "    if len(z1) >1:\n",
    "        centr[i,0] = np.average(x1)\n",
    "        centr[i,1] = np.average(y1)\n",
    "        centr[i,2] = np.max(z1)\n",
    "        centr[i,3] = w[k]\n",
    "        centr[i,4] = (l_list[i]+1)\n",
    "    print(centr[i,:])\n",
    "    i += 1   \n",
    "    \n",
    "print(len(centr))\n",
    "dataset = pd.DataFrame(centr)\n",
    "dataset.to_csv('./grid3_height_subset_unique_pts_output_centre.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9WBj87ck2Kc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "lidarProject.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
